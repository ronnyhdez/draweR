{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! Hi! I'm ronny and this site is my digital drawer made public. This means that you will find here raw notes that I usually take when I working with data and I have the need to document the process I'm following. Be aware that this is not an organized place. It's just a place where I put all my R notes to look for after (in case my future self forgets what I did in the past). If you want to check a place with tutorials and edited notes you can go and check my blog . It's in spanglish (some posts in Spanish, others in English and maybe some of them with a mix) and I usually source part of the material from here. If something works for you as a reference, great! Take it! Before this, all this notes where kept in my desk drawer What you can find here On your left side you will see the main table of contents On your right side you will see the table of contents from the specific section you are in. How this site was built? This site is hosted in GitHub. I just created the repo, went to configuration and enabled github pages. Then, with a bit of help of mkdocs and the material theme the site came to life. And now all my Rmarkdown notes fits in this site! Also, I was kind of \"obstinado\" having to repeat a couple of steps for each note that I wanted to deploy, so I created some R functions (around 3) to deal with this workflow and put everything together in a small R package that I called docmaker (Available just on GitHub) If you are new to this kind of documentation, I recommend you to check at least the package documentation, so you can find how to set-up everything to create your own site and give some freedom to your documentation. Who I am? I'm a desk biologist who likes to play around with my computer, specially with R, Linux, Vim and a couple of other tools.","title":"Welcome!"},{"location":"#welcome","text":"Hi! I'm ronny and this site is my digital drawer made public. This means that you will find here raw notes that I usually take when I working with data and I have the need to document the process I'm following. Be aware that this is not an organized place. It's just a place where I put all my R notes to look for after (in case my future self forgets what I did in the past). If you want to check a place with tutorials and edited notes you can go and check my blog . It's in spanglish (some posts in Spanish, others in English and maybe some of them with a mix) and I usually source part of the material from here. If something works for you as a reference, great! Take it! Before this, all this notes where kept in my desk drawer","title":"Welcome!"},{"location":"#what-you-can-find-here","text":"On your left side you will see the main table of contents On your right side you will see the table of contents from the specific section you are in.","title":"What you can find here"},{"location":"#how-this-site-was-built","text":"This site is hosted in GitHub. I just created the repo, went to configuration and enabled github pages. Then, with a bit of help of mkdocs and the material theme the site came to life. And now all my Rmarkdown notes fits in this site! Also, I was kind of \"obstinado\" having to repeat a couple of steps for each note that I wanted to deploy, so I created some R functions (around 3) to deal with this workflow and put everything together in a small R package that I called docmaker (Available just on GitHub) If you are new to this kind of documentation, I recommend you to check at least the package documentation, so you can find how to set-up everything to create your own site and give some freedom to your documentation.","title":"How this site was built?"},{"location":"#who-i-am","text":"I'm a desk biologist who likes to play around with my computer, specially with R, Linux, Vim and a couple of other tools.","title":"Who I am?"},{"location":"bash_scripts/","text":"Bash Terminal topics Probably a bit messy given that I use this space to export notes when solving things. Set up a timer I created a file call timer.sh Inside it contains this: #!/bin/bash date1=`date +%s`; while true; do echo -ne \"$(date -u --date @$((`date +%s` - $date1)) +%H:%M:%S)\\r\"; Then, to run the script without thinking too much, I created an alias: alias timer=\"bash /home/ronny/timer.sh\" So, any time I open the terminal, I can have a timer just typing timer Set up python conda environment Check if there are already envs: conda info --envs # conda environments: # base * /home/ronny/anaconda3 gee /home/ronny/anaconda3/envs/gee gpp /home/ronny/anaconda3/envs/gpp satellite /home/ronny/anaconda3/envs/satellite To activate/deactivate: conda activate conda deactivate There is a difference between: apt install spyder conda install spyder To create a new env: conda create --name gee python = 3.5","title":"Bash Terminal topics"},{"location":"bash_scripts/#bash-terminal-topics","text":"Probably a bit messy given that I use this space to export notes when solving things.","title":"Bash Terminal topics"},{"location":"bash_scripts/#set-up-a-timer","text":"I created a file call timer.sh Inside it contains this: #!/bin/bash date1=`date +%s`; while true; do echo -ne \"$(date -u --date @$((`date +%s` - $date1)) +%H:%M:%S)\\r\"; Then, to run the script without thinking too much, I created an alias: alias timer=\"bash /home/ronny/timer.sh\" So, any time I open the terminal, I can have a timer just typing timer","title":"Set up a timer"},{"location":"bash_scripts/#set-up-python-conda-environment","text":"Check if there are already envs: conda info --envs # conda environments: # base * /home/ronny/anaconda3 gee /home/ronny/anaconda3/envs/gee gpp /home/ronny/anaconda3/envs/gpp satellite /home/ronny/anaconda3/envs/satellite To activate/deactivate: conda activate conda deactivate There is a difference between: apt install spyder conda install spyder To create a new env: conda create --name gee python = 3.5","title":"Set up python conda environment"},{"location":"code_functions_challenges/","text":"Quick notes about short R code and functions things that usually I don\u2019t do and I tend to forget. Change specific values in all columns for NA\u2019s A data frame with -9999 values in many columns that need to be replace with NA \u2019s values: # libraries library(dplyr) ## ## Attaching package: 'dplyr' ## The following objects are masked from 'package:terra': ## ## intersect, union ## The following objects are masked from 'package:stats': ## ## filter, lag ## The following objects are masked from 'package:base': ## ## intersect, setdiff, setequal, union # Test data frame test <- tribble(~a, ~b, ~c, \"a\", 2, -9999, \"b\", 3, 5, \"c\", -9999, 6, \"d\", -9999, -9999) # Solution test %>% mutate_all(~na_if(., -9999)) ## # A tibble: 4 \u00d7 3 ## a b c ## <chr> <dbl> <dbl> ## 1 a 2 NA ## 2 b 3 5 ## 3 c NA 6 ## 4 d NA NA","title":"Code functions challenges"},{"location":"code_functions_challenges/#change-specific-values-in-all-columns-for-nas","text":"A data frame with -9999 values in many columns that need to be replace with NA \u2019s values: # libraries library(dplyr) ## ## Attaching package: 'dplyr' ## The following objects are masked from 'package:terra': ## ## intersect, union ## The following objects are masked from 'package:stats': ## ## filter, lag ## The following objects are masked from 'package:base': ## ## intersect, setdiff, setequal, union # Test data frame test <- tribble(~a, ~b, ~c, \"a\", 2, -9999, \"b\", 3, 5, \"c\", -9999, 6, \"d\", -9999, -9999) # Solution test %>% mutate_all(~na_if(., -9999)) ## # A tibble: 4 \u00d7 3 ## a b c ## <chr> <dbl> <dbl> ## 1 a 2 NA ## 2 b 3 5 ## 3 c NA 6 ## 4 d NA NA","title":"Change specific values in all columns for NA\u2019s"},{"location":"data_table/","text":"Translating a dplyr pipeline to data table The problem was that a project had local csv files with many rows. When cleaning the data using dplyr this would consume a lot of the memory and take a lot of time to produce a result. So, an option was to implement the package data.table to be able to handle all this data in a local computer. This was the original data pipeline: pixels_clean <- pixels %>% separate(file_id, into = c(\"folder\", \"file_id\"), sep = \"/\") %>% mutate(file_id = str_remove(file_id, \".csv\")) %>% mutate(location = str_extract(geo, \"\\\\[(.*?)\\\\]\") ) %>% separate(col = \"location\", into = c(\"lat\", \"long\"), sep = \",\") %>% mutate(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\")) %>% select(-folder, -geo) %>% separate(file_id, into = c(\"first\", \"second\", \"tnk\"), remove = FALSE) %>% select(-second, -tnk) %>% separate(first, into = c(\"date\", \"time\"), sep = \"T\") %>% mutate(date = ymd(date)) The translation to data table: setDT(pixels_sr) pixels_sr[, c(\"folder_1\", \"folder_2\", \"file_id\") := tstrsplit(file_id, \"/\", fixed = TRUE)] pixels_sr[ , \":=\"(file_id = str_remove(file_id, \".csv\"))] pixels_sr[ , \":=\"(location = str_extract(geo, \"\\\\[(.*?)\\\\]\"))] pixels_sr[, c(\"lat\", \"long\") := tstrsplit(location, \",\", fixed = TRUE)] pixels_sr[ , \":=\"(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\"))] pixels_sr[, \":=\"(date = ymd(file_id))] pixels_sr[, c(\"file_id\", \"system_index\", \"folder_1\", \"folder_2\", \"geo\", \"location\") := NULL] Other tips: If we have a column with more than ~40 groups, we should create a key: setkey(pft, columna_con_muchos_grupos) The sintaxis to summarise per groups will be: check_mean <- pft[ , .(mean_evi = mean(evi, na.rm = TRUE)), by = fecha] Sintaxis for creating a new column with some column formulas: pft[ , \":=\"(evi = (2.5 *(b8 - b4)) / (b8 + (2.4 * b4) + 1000))]","title":"Data table"},{"location":"data_table/#translating-a-dplyr-pipeline-to-data-table","text":"The problem was that a project had local csv files with many rows. When cleaning the data using dplyr this would consume a lot of the memory and take a lot of time to produce a result. So, an option was to implement the package data.table to be able to handle all this data in a local computer. This was the original data pipeline: pixels_clean <- pixels %>% separate(file_id, into = c(\"folder\", \"file_id\"), sep = \"/\") %>% mutate(file_id = str_remove(file_id, \".csv\")) %>% mutate(location = str_extract(geo, \"\\\\[(.*?)\\\\]\") ) %>% separate(col = \"location\", into = c(\"lat\", \"long\"), sep = \",\") %>% mutate(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\")) %>% select(-folder, -geo) %>% separate(file_id, into = c(\"first\", \"second\", \"tnk\"), remove = FALSE) %>% select(-second, -tnk) %>% separate(first, into = c(\"date\", \"time\"), sep = \"T\") %>% mutate(date = ymd(date)) The translation to data table: setDT(pixels_sr) pixels_sr[, c(\"folder_1\", \"folder_2\", \"file_id\") := tstrsplit(file_id, \"/\", fixed = TRUE)] pixels_sr[ , \":=\"(file_id = str_remove(file_id, \".csv\"))] pixels_sr[ , \":=\"(location = str_extract(geo, \"\\\\[(.*?)\\\\]\"))] pixels_sr[, c(\"lat\", \"long\") := tstrsplit(location, \",\", fixed = TRUE)] pixels_sr[ , \":=\"(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\"))] pixels_sr[, \":=\"(date = ymd(file_id))] pixels_sr[, c(\"file_id\", \"system_index\", \"folder_1\", \"folder_2\", \"geo\", \"location\") := NULL]","title":"Translating a dplyr pipeline to data table"},{"location":"data_table/#other-tips","text":"If we have a column with more than ~40 groups, we should create a key: setkey(pft, columna_con_muchos_grupos) The sintaxis to summarise per groups will be: check_mean <- pft[ , .(mean_evi = mean(evi, na.rm = TRUE)), by = fecha] Sintaxis for creating a new column with some column formulas: pft[ , \":=\"(evi = (2.5 *(b8 - b4)) / (b8 + (2.4 * b4) + 1000))]","title":"Other tips:"},{"location":"google_drive_api/","text":"A mockup documented function to connect with the google drive API through R, check the files that exist in the drive folder, compare to what you have in your local folder and download just those that you don\u2019t have locally. Could be part of some workflow in an organization that uses google drive as their site to keep their data files (like a research lab) #' @import dplyr NULL #' @title Download data from google drive #' #' @author Ronny Alexander Hern\u00e1ndez Mora #' #' @description This function will check in a local folder, the existing files #' and compare which ones are missing from an specific folder in google drive. #' It will download the missing files #' #' @param drive_path The folder in google drive containing the files #' @param local_directory The local folder in which we want to download the #' files from google drive. #' #' @example #' \\dontrun{ #' get_drive_data(drive_path = \"data_workflows/data\", #' local_directory = \"datos\") #'} #' get_drive_data <- function(drive_path, local_directory) { options(gargle_oauth_email = \"my_email@gmail.com\") # Revisar archivos locales archivos_existentes <- fs::dir_ls(local_directory) %>% stringr::str_remove(paste0(local_directory, \"/\")) # Revisar archivos en drive camino <- drive_path # Check data available archivos_drive <- googledrive::drive_ls(path = camino) # archivos_drive <- archivos %>% # select(name) # Obtener nombres de archivos faltantes # Suponiendo que siempre tenemos mas archivos en drive archivos_faltantes <- archivos_drive %>% filter(!name %in% archivos_existentes) # Loop para traerse archivos que estan en drive pero no locales for (i in archivos_faltantes$name) { archivos_faltantes %>% select(id) %>% slice(1) %>% pull() %>% googledrive::drive_download( path = paste0(\"datos/\", i), overwrite = TRUE ) } } After the function is loaded in your Global environment, coupled with a map() and if all the data files have the same variables, we can read everything together in just one data frame: # Check drive and download data ------------------------------ get_drive_data(drive_path = \"data_workflows/data\", local_directory = \"datos\") # Read data -------------------------------------------------- # Create object with files of interest files <- dir_ls(path = \"datos\", glob = \"datos/principe_*\") principe <- files %>% map_dfr(read_csv, .id = \"file_id\")","title":"Google drive api"},{"location":"linux/","text":"Installing RStudio in Ubuntu Instalacion de R en ubuntu 20.10 desde binario de RStudio Instalar gdebi sudo apt update sudo apt install gdebi-core Especificar version de R export R_VERSION=4.1.1 Descargar binario de R curl -O https://cdn.rstudio.com/r/ubuntu-2004/pkgs/r-${R_VERSION}_1_amd64.deb Instalar binario de R sudo gdebi r-${R_VERSION}_1_amd64.deb Validar version de R /opt/R/${R_VERSION}/bin/R --version Crear los symlink sudo ln -s /opt/R/${R_VERSION}/bin/R /usr/local/bin/R sudo ln -s /opt/R/${R_VERSION}/bin/Rscript /usr/local/bin/Rscript Instalaci'on de RStudio en ubuntu 20.10 Descarga RStudio desktop desde el sitio https://www.rstudio.com/products/rstudio/download/#download Validar en que carpeta de la computadora quedo el archivo comprimido instalar con gdebi rstudio sudo gdebi Downloads/rstudio-1.4.1717-amd64.deb Actualizar paquetes. Al tener la nueva instalacion, los paquetes que tenia instalados, ya no los tengo. En lugar de ir instalando cada uno por separado, lo que hago es que el directorio donde tenia las instalaciones de los paquetes, la copio en la nueva direccion. /home/ronny/R/x86_64-pc-linux-gnu-library/4.1 Luego, abro RStudio, en el panel de paquetes selecciono la opcion update , luego Select all y por ultimo Install Updates . Asi se instalaran todos los paquetes que tenia anteriormente. Apache configuration steps for shiny server Para saber si un archivo es un symlink: file archivo Instalar dependencias: sudo apt-get install apache2 sudo apt-get install libapache2-mod-proxy-html sudo apt-get install libxml2-dev Habilitar modulos sudo a2enmod proxy sudo a2enmod proxy_http sudo a2enmod proxy_wstunnel sudo a2enmod rewrite Configurar archivo /etc/apache2/sites-available/000-default.conf Dejar lo siguiente: (se puede borrar todo lo demas) <VirtualHost *:80> <Proxy *> Allow from localhost </Proxy> RewriteEngine on RewriteCond %{HTTP:Upgrade} =websocket RewriteRule /(.*) ws://localhost:3838/$1 [P,L] RewriteCond %{HTTP:Upgrade} !=websocket RewriteRule /(.*) http://localhost:3838/$1 [P,L] ProxyPass / http://localhost:3838/ ProxyPassReverse / http://localhost:3838/ ProxyRequests Off </VirtualHost> Reiniciar apache sudo systemctl restart apache2 Ir a revisar la direccion ip a ver si ya no tenemos que usar la puerta","title":"Installing RStudio in Ubuntu"},{"location":"linux/#installing-rstudio-in-ubuntu","text":"Instalacion de R en ubuntu 20.10 desde binario de RStudio","title":"Installing RStudio in Ubuntu"},{"location":"linux/#instalar-gdebi","text":"sudo apt update sudo apt install gdebi-core","title":"Instalar gdebi"},{"location":"linux/#especificar-version-de-r","text":"export R_VERSION=4.1.1","title":"Especificar version de R"},{"location":"linux/#descargar-binario-de-r","text":"curl -O https://cdn.rstudio.com/r/ubuntu-2004/pkgs/r-${R_VERSION}_1_amd64.deb","title":"Descargar binario de R"},{"location":"linux/#instalar-binario-de-r","text":"sudo gdebi r-${R_VERSION}_1_amd64.deb","title":"Instalar binario de R"},{"location":"linux/#validar-version-de-r","text":"/opt/R/${R_VERSION}/bin/R --version","title":"Validar version de R"},{"location":"linux/#crear-los-symlink","text":"sudo ln -s /opt/R/${R_VERSION}/bin/R /usr/local/bin/R sudo ln -s /opt/R/${R_VERSION}/bin/Rscript /usr/local/bin/Rscript","title":"Crear los symlink"},{"location":"linux/#instalacion-de-rstudio-en-ubuntu-2010","text":"Descarga RStudio desktop desde el sitio https://www.rstudio.com/products/rstudio/download/#download Validar en que carpeta de la computadora quedo el archivo comprimido","title":"Instalaci'on de RStudio en ubuntu 20.10"},{"location":"linux/#instalar-con-gdebi-rstudio","text":"sudo gdebi Downloads/rstudio-1.4.1717-amd64.deb","title":"instalar con gdebi rstudio"},{"location":"linux/#actualizar-paquetes","text":"Al tener la nueva instalacion, los paquetes que tenia instalados, ya no los tengo. En lugar de ir instalando cada uno por separado, lo que hago es que el directorio donde tenia las instalaciones de los paquetes, la copio en la nueva direccion. /home/ronny/R/x86_64-pc-linux-gnu-library/4.1 Luego, abro RStudio, en el panel de paquetes selecciono la opcion update , luego Select all y por ultimo Install Updates . Asi se instalaran todos los paquetes que tenia anteriormente.","title":"Actualizar paquetes."},{"location":"linux/#apache-configuration-steps-for-shiny-server","text":"Para saber si un archivo es un symlink: file archivo","title":"Apache configuration steps for shiny server"},{"location":"linux/#instalar-dependencias","text":"sudo apt-get install apache2 sudo apt-get install libapache2-mod-proxy-html sudo apt-get install libxml2-dev","title":"Instalar dependencias:"},{"location":"linux/#habilitar-modulos","text":"sudo a2enmod proxy sudo a2enmod proxy_http sudo a2enmod proxy_wstunnel sudo a2enmod rewrite","title":"Habilitar modulos"},{"location":"linux/#configurar-archivo-etcapache2sites-available000-defaultconf","text":"Dejar lo siguiente: (se puede borrar todo lo demas) <VirtualHost *:80> <Proxy *> Allow from localhost </Proxy> RewriteEngine on RewriteCond %{HTTP:Upgrade} =websocket RewriteRule /(.*) ws://localhost:3838/$1 [P,L] RewriteCond %{HTTP:Upgrade} !=websocket RewriteRule /(.*) http://localhost:3838/$1 [P,L] ProxyPass / http://localhost:3838/ ProxyPassReverse / http://localhost:3838/ ProxyRequests Off </VirtualHost>","title":"Configurar archivo /etc/apache2/sites-available/000-default.conf"},{"location":"linux/#reiniciar-apache","text":"sudo systemctl restart apache2","title":"Reiniciar apache"},{"location":"linux/#ir-a-revisar-la-direccion-ip-a-ver-si-ya-no-tenemos-que-usar-la-puerta","text":"","title":"Ir a revisar la direccion ip a ver si ya no tenemos que usar la puerta"},{"location":"questions_in_r/","text":"Create questions with yesno package If we have functions that require the confirmation of the user, we can use the yesno package to create questions and the answer options: library(yesno) publicar <- function(){ respuesta <- yesno::yesno(\"\u00bfDesea publicar las notas?\", yes = \"Estoy seguro de publicarlas\", no = \"No, es un error\", no = \"NOOO, yo no quiero publicar nada\") if (respuesta == TRUE) { print(\"Los correos han sido enviados\") } else { print(\"No se envio nada\") } } #publicar()","title":"Create questions with `yesno` package"},{"location":"questions_in_r/#create-questions-with-yesno-package","text":"If we have functions that require the confirmation of the user, we can use the yesno package to create questions and the answer options: library(yesno) publicar <- function(){ respuesta <- yesno::yesno(\"\u00bfDesea publicar las notas?\", yes = \"Estoy seguro de publicarlas\", no = \"No, es un error\", no = \"NOOO, yo no quiero publicar nada\") if (respuesta == TRUE) { print(\"Los correos han sido enviados\") } else { print(\"No se envio nada\") } } #publicar()","title":"Create questions with yesno package"},{"location":"r_spatial_tutorial/","text":"R spatial notes All notes related to experiments to deal and learn about using spatial data with R. Exporting a COG (Cloud Optimized Geotiff) file from GEE The idea is to document steps to export from Google Earth Engine a COG file (or several) to Google Drive to be imported latter in R for analysis. As a first approach, I followed a tutorial from the Google documentation: . The code below is a copy/paste from the GEE IDE: // Load a landsat image and select three bands. var landsat = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_123032_20140515') .select(['B4', 'B3', 'B2']); // Create a geometry representing an export region. var geometry = ee.Geometry.Rectangle([116.2621, 39.8412, 116.4849, 40.01236]); // Retrieve the projection information from a band of the original image. // Call getInfo() on the projection to request a client-side object containing // the crs and transform information needed for the client-side Export function. var projection = landsat.select('B2').projection().getInfo(); // Export a cloud-optimized GeoTIFF. Export.image.toDrive({ image: landsat, description: 'imageToCOGeoTiffExample', crs: projection.crs, crsTransform: projection.transform, region: geometry, folder: \"GEE_testing\", fileFormat: 'GeoTIFF', formatOptions: { cloudOptimized: true } }); After the COG file was exported to my Google Drive, I downloaded to my data folder. Then, this file was imported to my R session with the help of the terra package: library(terra) check <- rast(\"data/imageToCOGeoTiffExample.tif\") And, to validate it, I plotted the file using the terra function: plot(check) plotRGB(check, axes = TRUE, stretch = \"lin\", main = \"Landsat True Color Composite\") References https://rspatial.org/terra/pkg/1-introduction.html https://geocompr.robinlovelace.net/read-write.html#raster-data-read https://rspatial.org/raster/rs/2-exploration.html https://developers.google.com/earth-engine/guides/exporting Updating GDAL in Ubuntu For using the terra package or other spatial packages in R, it\u2019s necessary to install in your system GDAL . There are several steps to follow to do this. In my case, I had already GDAL on my system but it was outdated. $ gdalinfo --version GDAL 3.0.4, released 2020/01/28 So, I removed first the system packages: sudo apt remove libgdal-dev sudo apt remove libproj-dev sudo apt remove gdal-bin Then I proceed to add the PPA ubuntugis sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable Finally, I installed the necessary packages: sudo apt-get install gdal-bin sudo apt-get install libgdal-dev libgeos-dev libproj-dev sudo apt update sudo apt upgrade sudo apt autoremove And now, my GDAL version is: $ gdalinfo --version GDAL 3.3.2, released 2021/09/01 terra package tutorial All the code and examples here were created using the information in rspatial.org Downloading example data if (!fs::dir_exists(\"data\")) { dir.create(\"data\", showWarnings = FALSE) } if (!file.exists(\"data/rs/samples.rds\")) { download.file(\"https://biogeo.ucdavis.edu/data/rspatial/rs.zip\", dest = \"data/rs.zip\") unzip(\"data/rs.zip\", exdir=\"data\") } Working with MODIS data The documentation states that we should work with the luna package, but it\u2019s not on CRAN, so I downloaded directly from the GitHub # remotes::install_github(\"rspatial/luna\") library(terra) library(luna) # Check products available through package API's prod <- getProducts() head(prod) # Check just the MODIS products modis <- getProducts(\"^MOD|^MYD|^MCD\") head(modis) # To redirect to MODIS info webpage ## Examples comes with MOD09A1 ## I'm interested in MOD09GA productInfo(\"MOD09GA\") # Queremos descargar los datos ## Necesitamos area de interes ## Fecha de inicio y de fin nicoya <- geodata::gadm(\"Costa Rica\", level = 1, path = \".\") nicoya guanacaste <- nicoya[nicoya$NAME_1 == \"Guanacaste\", ] # Plot area plot(nicoya, col = \"light gray\") lines(guanacaste, col = \"red\", lwd = 2) # Check MODIS data available for the area of interest mf <- luna::getModis(product = \"MOD09GA\", start_date = \"2015-01-01\", end_date = \"2015-01-07\", aoi = guanacaste, download = FALSE) mf # Let's download some data username <- Sys.getenv(\"EARTHDATA_USER\") passwd <- Sys.getenv(\"EARTHDATA_PASSWD\") mf <- luna::getModis(product = \"MOD09GA\", start_date = \"2015-01-01\", end_date = \"2015-01-07\", aoi = guanacaste, download = TRUE, path = here::here(\"data\"), username = username, password = passwd) mf # At this point, we should have the data in the path indicated # Explore the downloaded data: library(fs) library(terra) file <- file.path(here::here(), \"data/MOD09GA.A2015006.h09v07.006.2015295062629.hdf\") r <- rast(file) datadir <- file.path(dirname(tempdir()), \"_modis\") mf <- file.path(datadir, \"MOD09A1.A2009361.h21v08.006.2015198070255.hdf\") library(terra) r <- rast(mf[1]) r I have the problem that I cannot read the downloaded files # with same steps as tutorial product <- \"MOD09A1\" start <- \"2010-01-01\" end <- \"2010-01-07\" ken <- geodata::gadm(\"Kenya\", level=1, path=\".\") ken i <- ken$NAME_1 == \"Marsabit\" aoi <- ken[i,] plot(ken, col=\"light gray\") lines(aoi, col=\"red\", lwd=2) mf <- luna::getModis(product, start, end, aoi=aoi, download = FALSE) mf datadir <- file.path(dirname(tempdir()), \"_modis\") dir.create(datadir, showWarnings=FALSE) mf <- luna::getModis(product, start, end, aoi=aoi, download=TRUE, path=datadir, username = username, password = passwd) mf datadir <- file.path(dirname(tempdir()), \"_modis\") mf <- file.path(datadir, \"MOD09A1.A2009361.h21v08.006.2015198070255.hdf\") library(terra) r <- terra::rast(mf[1]) r https://rspatial.org/terra/modis/4-quality.html","title":"R spatial notes"},{"location":"r_spatial_tutorial/#r-spatial-notes","text":"All notes related to experiments to deal and learn about using spatial data with R.","title":"R spatial notes"},{"location":"r_spatial_tutorial/#exporting-a-cog-cloud-optimized-geotiff-file-from-gee","text":"The idea is to document steps to export from Google Earth Engine a COG file (or several) to Google Drive to be imported latter in R for analysis. As a first approach, I followed a tutorial from the Google documentation: . The code below is a copy/paste from the GEE IDE: // Load a landsat image and select three bands. var landsat = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_123032_20140515') .select(['B4', 'B3', 'B2']); // Create a geometry representing an export region. var geometry = ee.Geometry.Rectangle([116.2621, 39.8412, 116.4849, 40.01236]); // Retrieve the projection information from a band of the original image. // Call getInfo() on the projection to request a client-side object containing // the crs and transform information needed for the client-side Export function. var projection = landsat.select('B2').projection().getInfo(); // Export a cloud-optimized GeoTIFF. Export.image.toDrive({ image: landsat, description: 'imageToCOGeoTiffExample', crs: projection.crs, crsTransform: projection.transform, region: geometry, folder: \"GEE_testing\", fileFormat: 'GeoTIFF', formatOptions: { cloudOptimized: true } }); After the COG file was exported to my Google Drive, I downloaded to my data folder. Then, this file was imported to my R session with the help of the terra package: library(terra) check <- rast(\"data/imageToCOGeoTiffExample.tif\") And, to validate it, I plotted the file using the terra function: plot(check) plotRGB(check, axes = TRUE, stretch = \"lin\", main = \"Landsat True Color Composite\")","title":"Exporting a COG (Cloud Optimized Geotiff) file from GEE"},{"location":"r_spatial_tutorial/#references","text":"https://rspatial.org/terra/pkg/1-introduction.html https://geocompr.robinlovelace.net/read-write.html#raster-data-read https://rspatial.org/raster/rs/2-exploration.html https://developers.google.com/earth-engine/guides/exporting","title":"References"},{"location":"r_spatial_tutorial/#updating-gdal-in-ubuntu","text":"For using the terra package or other spatial packages in R, it\u2019s necessary to install in your system GDAL . There are several steps to follow to do this. In my case, I had already GDAL on my system but it was outdated. $ gdalinfo --version GDAL 3.0.4, released 2020/01/28 So, I removed first the system packages: sudo apt remove libgdal-dev sudo apt remove libproj-dev sudo apt remove gdal-bin Then I proceed to add the PPA ubuntugis sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable Finally, I installed the necessary packages: sudo apt-get install gdal-bin sudo apt-get install libgdal-dev libgeos-dev libproj-dev sudo apt update sudo apt upgrade sudo apt autoremove And now, my GDAL version is: $ gdalinfo --version GDAL 3.3.2, released 2021/09/01","title":"Updating GDAL in Ubuntu"},{"location":"r_spatial_tutorial/#terra-package-tutorial","text":"All the code and examples here were created using the information in rspatial.org","title":"terra package tutorial"},{"location":"r_spatial_tutorial/#downloading-example-data","text":"if (!fs::dir_exists(\"data\")) { dir.create(\"data\", showWarnings = FALSE) } if (!file.exists(\"data/rs/samples.rds\")) { download.file(\"https://biogeo.ucdavis.edu/data/rspatial/rs.zip\", dest = \"data/rs.zip\") unzip(\"data/rs.zip\", exdir=\"data\") }","title":"Downloading example data"},{"location":"r_spatial_tutorial/#working-with-modis-data","text":"The documentation states that we should work with the luna package, but it\u2019s not on CRAN, so I downloaded directly from the GitHub # remotes::install_github(\"rspatial/luna\") library(terra) library(luna) # Check products available through package API's prod <- getProducts() head(prod) # Check just the MODIS products modis <- getProducts(\"^MOD|^MYD|^MCD\") head(modis) # To redirect to MODIS info webpage ## Examples comes with MOD09A1 ## I'm interested in MOD09GA productInfo(\"MOD09GA\") # Queremos descargar los datos ## Necesitamos area de interes ## Fecha de inicio y de fin nicoya <- geodata::gadm(\"Costa Rica\", level = 1, path = \".\") nicoya guanacaste <- nicoya[nicoya$NAME_1 == \"Guanacaste\", ] # Plot area plot(nicoya, col = \"light gray\") lines(guanacaste, col = \"red\", lwd = 2) # Check MODIS data available for the area of interest mf <- luna::getModis(product = \"MOD09GA\", start_date = \"2015-01-01\", end_date = \"2015-01-07\", aoi = guanacaste, download = FALSE) mf # Let's download some data username <- Sys.getenv(\"EARTHDATA_USER\") passwd <- Sys.getenv(\"EARTHDATA_PASSWD\") mf <- luna::getModis(product = \"MOD09GA\", start_date = \"2015-01-01\", end_date = \"2015-01-07\", aoi = guanacaste, download = TRUE, path = here::here(\"data\"), username = username, password = passwd) mf # At this point, we should have the data in the path indicated # Explore the downloaded data: library(fs) library(terra) file <- file.path(here::here(), \"data/MOD09GA.A2015006.h09v07.006.2015295062629.hdf\") r <- rast(file) datadir <- file.path(dirname(tempdir()), \"_modis\") mf <- file.path(datadir, \"MOD09A1.A2009361.h21v08.006.2015198070255.hdf\") library(terra) r <- rast(mf[1]) r I have the problem that I cannot read the downloaded files # with same steps as tutorial product <- \"MOD09A1\" start <- \"2010-01-01\" end <- \"2010-01-07\" ken <- geodata::gadm(\"Kenya\", level=1, path=\".\") ken i <- ken$NAME_1 == \"Marsabit\" aoi <- ken[i,] plot(ken, col=\"light gray\") lines(aoi, col=\"red\", lwd=2) mf <- luna::getModis(product, start, end, aoi=aoi, download = FALSE) mf datadir <- file.path(dirname(tempdir()), \"_modis\") dir.create(datadir, showWarnings=FALSE) mf <- luna::getModis(product, start, end, aoi=aoi, download=TRUE, path=datadir, username = username, password = passwd) mf datadir <- file.path(dirname(tempdir()), \"_modis\") mf <- file.path(datadir, \"MOD09A1.A2009361.h21v08.006.2015198070255.hdf\") library(terra) r <- terra::rast(mf[1]) r","title":"Working with MODIS data"},{"location":"r_spatial_tutorial/#httpsrspatialorgterramodis4-qualityhtml","text":"","title":"https://rspatial.org/terra/modis/4-quality.html"},{"location":"stringr_tips/","text":"How many hours have I spent looking how to solve a regex? A lot! So here I have some quick notes on things that I have solved before and forget about it pretty often. How to extract numbers from a string Sometimes, I need to extract just the numbers that I can find in a string. To achieve this, I can use the following function: library(stringr) string_with_numbers <- c(\"01 uno\", \"02 dos\") str_extract(string_with_numbers , \"\\\\d+\") ## [1] \"01\" \"02\" Extract string between brackets library(stringr) library(tibble) library(dplyr) library(tidyr) ## ## Attaching package: 'tidyr' ## The following object is masked from 'package:terra': ## ## extract ## The data frames with the column that I need check <- tribble( ~geo, \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94739867829001,44.3105986723403]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94714795170373,44.310596361431216]}\", \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9468972251475,44.31059404997191]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9466464986213,44.31059173796237]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94639577212517,44.3105894254026]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9461450456591,44.310587112292595]}\" ) ## Solution 1 (Didn't work) check %>% mutate(test = str_extract(geo, \"\\\\[|\\\\]\") ) %>% select(test) ## # A tibble: 6 \u00d7 1 ## test ## <chr> ## 1 [ ## 2 [ ## 3 [ ## 4 [ ## 5 [ ## 6 [ # Solution 2 (This one works!) check %>% mutate(test = str_extract(geo, \"\\\\[(.*?)\\\\]\") ) %>% select(test) %>% separate(col = \"test\", into = c(\"lat\", \"long\"), sep = \",\") %>% mutate(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\")) ## # A tibble: 6 \u00d7 2 ## lat long ## <chr> <chr> ## 1 -79.94739867829001 44.3105986723403 ## 2 -79.94714795170373 44.310596361431216 ## 3 -79.9468972251475 44.31059404997191 ## 4 -79.9466464986213 44.31059173796237 ## 5 -79.94639577212517 44.3105894254026 ## 6 -79.9461450456591 44.310587112292595","title":"Stringr tips"},{"location":"stringr_tips/#how-to-extract-numbers-from-a-string","text":"Sometimes, I need to extract just the numbers that I can find in a string. To achieve this, I can use the following function: library(stringr) string_with_numbers <- c(\"01 uno\", \"02 dos\") str_extract(string_with_numbers , \"\\\\d+\") ## [1] \"01\" \"02\"","title":"How to extract numbers from a string"},{"location":"stringr_tips/#extract-string-between-brackets","text":"library(stringr) library(tibble) library(dplyr) library(tidyr) ## ## Attaching package: 'tidyr' ## The following object is masked from 'package:terra': ## ## extract ## The data frames with the column that I need check <- tribble( ~geo, \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94739867829001,44.3105986723403]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94714795170373,44.310596361431216]}\", \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9468972251475,44.31059404997191]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9466464986213,44.31059173796237]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.94639577212517,44.3105894254026]}\" , \"{\\\"geodesic\\\":false,\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-79.9461450456591,44.310587112292595]}\" ) ## Solution 1 (Didn't work) check %>% mutate(test = str_extract(geo, \"\\\\[|\\\\]\") ) %>% select(test) ## # A tibble: 6 \u00d7 1 ## test ## <chr> ## 1 [ ## 2 [ ## 3 [ ## 4 [ ## 5 [ ## 6 [ # Solution 2 (This one works!) check %>% mutate(test = str_extract(geo, \"\\\\[(.*?)\\\\]\") ) %>% select(test) %>% separate(col = \"test\", into = c(\"lat\", \"long\"), sep = \",\") %>% mutate(lat = str_extract(lat, \"-?[0-9.]+\"), long = str_extract(long, \"-?[0-9.]+\")) ## # A tibble: 6 \u00d7 2 ## lat long ## <chr> <chr> ## 1 -79.94739867829001 44.3105986723403 ## 2 -79.94714795170373 44.310596361431216 ## 3 -79.9468972251475 44.31059404997191 ## 4 -79.9466464986213 44.31059173796237 ## 5 -79.94639577212517 44.3105894254026 ## 6 -79.9461450456591 44.310587112292595","title":"Extract string between brackets"},{"location":"vim_notes/","text":"How to set up vim There are two config files: one for vim, otherone for nvim vim: ~/.vimrc nvim: ~/.config/nvim/init.vim I cannot find at this point a config file for vim O.o So, I will just create a .vimrc under my home: Now, given that I have installed in my computer vim and nvim, the way that the configuration files interact, seems that nvim takes prevalence. So, all the changes I made in the ~/.vimrc are not going to be stablished unless I source the vimrc in the init.vim As an example, this is the way my init.vim looks like: \" ============================= \" Source vimrc \" ============================ source ~/.vimrc \" ============================= \" Plugins \" ============================= call plug#begin() Plug 'JuliaEditorSupport/julia-vim' Plug 'kdheepak/JuliaFormatter.vim' Plug 'jpalardy/vim-slime' Plug 'neoclide/coc.nvim', {'branch': 'release'} Plug 'morhetz/gruvbox' call plug#end() \" ============================= \" VIM Slime \" ============================= let g:slime_target = \"neovim\" Creating and modifying the vimrc vim ~/.vimrc Settings for vim First I'm going to edit the vimrc file. One trick to try the configurations that I want, is that if I'm working on vim I can go to normal mode and try for example :set relative number and that will include the modification for that vim session. Customizing vim (plugins) Plugins are for this. Different from the settings that are things that comes already with vim, the plugins are made for this. To use plugins, we need a plugin manager. One of the most used ones is the vim-plug In order to use plugins (after installing the vim-plug) our .vimrc file should contain a section that starts and finish with this: call plug#begin('~/.vim/plugged') call plug#end() Now, if we want to install a plugin, we should write in the middle of those two calls the plugin. Save and then run :PlugInstall And that's it. It will download and install the files needed. As an example, to change a color scheme we can do: call plug#begin('~/.vim/plugged') Plug 'gruvbox-community/gruvbox' call plug#end() After the installation, we can set: :colorscheme gruvbox If I want to know the pluggins installed, and given that we are using the vim-plug we can check the pluggins in use with: :PlugStatus Working with vim and git Is kind of bothering to exit vim in order to commit changes in the git repository, so a way to do it is to use the bang :! to execute shell commands. :!git status :!git commit -m \"Ref #2 my changes done\" :!git push Here we can use the % to indicate current file: :!git add % :!git checkout % To be honest, its easier to open a new window with tmux and execute all terminal commands from there than from the vim session. It's less tipying. Workflow When changing the .vimrc file Errors Section with some of the errors that I have faced and followed steps to solve them. .coc nodejs not executable When opening a vim session, always this message will pop-up: \"node\" is not executable, checkout https://nodejs.org/en/download/ To install nodejs and avoid this problem, I did: curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs rf not starting R session Given that the rf is not working when opening a R file, one of the solutions is to indicate the R path in the .vimrc file, so I included it let R_path = '~/R/x86_64-pc-linux-gnu-library/4.2' Nonetheless, it's still not working. New start So, given that my configuration wasn't working who knows why, I just commented all the .vimrc file and start over again checking what worked and what no. After commenting my .vimrc , I reloaded it. I opened a vim_test.R file, hit \\rf and it worked! Now that it worked, I went through the .vimrc and start uncommenting some of the things that I thought would not affect again nvim-r. The final file looks like this one: \" No compatibility with vi to avoid problems \"set nocompatible \" Source vimrc file if specific project have one \"set exrc \" Cursor as a block set guicursor= \" Use relative numbers in files set relativenumber \" Line where I'm positioned is the real line number set nu \" Avoid leaving highligth after a search is done \"set nohlsearch \" No saving or keeping buffer in the background set hidden \" Indentetation configuration set tabstop=4 softtabstop=4 set shiftwidth=4 set expandtab set smartindent \" Start scrolling until 8 spaces away set scrolloff=8 \" Create extra column set signcolumn=yes \" Mark 80 characters line set colorcolumn=80 \" Enable type file detection \"filetype on \" Enable plugins and load plugins for the detected filetype \"filetype plugin on \" Load an indent file for the detected file type \"filetype indent on \" Set the leader key \"let mapleader=\" \" \" Set encoding \"set encoding=utf-8 \" Plugins \" gruvbox to change color schema \" powerline to obtain bar in bottom with git/project status call plug#begin() \"Plug 'gruvbox-community/gruvbox' Plug 'jalvesaq/Nvim-R' \" To work with vim and R Plug 'preservim/nerdtree' \" View the files Plug 'ncm2/ncm2' \" Auto-complete R commands Plug 'gaalcaras/ncm-R' \" Auto complete R commands call plug#end() \" NERDTree configuration test nnoremap <C-n> :NERDTree<CR> \" Set the R path for plugin nvim-r \"let R_path = '~/R/x86_64-pc-linux-gnu-library/4.2' vim workflow for R projects Ok, I don't want to spend more time on this configuration thing. So I started using vim to work on my R project just to feel the main pains when switching from RStudio. Along the way, if there is too much pain because of lack of some sort of functionality that I was too attached to it, I will change the .vimrc file to try to relieve some pain. \\rf Connect to R Console \\rq Quit R Console \\d Run current line and move to the next line \\l Run current line, but cursor will stay on the same line. \\pp Run paragraph. But cursor will stay on the same block. \\pd Runs block and move to the next one \\ss Execute a block of selected code . This has to be done with visual mode \\aa Run entire script \\ro Open the \"Global Environment\" ctrl + w + l Jump to left panel ctrl + w + h Jump to right panel If I made a change on the ~/.vimrc file, I can source it with :source ~/.vimcr If I have installed the pluggin NERDTree , I need to remap some keys. At the moment I have in my ~/.vimrc file the line: nnoremap <C-n> :NERDTree<CR> , so I don't have to do :NERDTree to open the file browser. Now this can be done with: ctrl + n Open file browser on left side by default. Inside the file tree browser, I can move with the arrows. To expand one folder and show contents, I can hit ENTER . Doing the same in an open folder, will close it. To move out from the NERDTree browser I can ctrl + w + w so I will be jumping panels from left to right. References Plugin repos https://github.com/gaalcaras/ncm-R https://github.com/preservim/nerdtree https://github.com/jamespeapen/Nvim-R/wiki/Use Sites that can be useful: https://github.com/nodesource/distributions/blob/master/README.md#debinstall http://manuals.bioinformatics.ucr.edu/home/programming-in-r/vim-r https://hpcc.ucr.edu/manuals_linux-cluster_terminalIDE.html https://gist.github.com/tgirke/7a7c197b443243937f68c422e5471899","title":"Vim notes"},{"location":"vim_notes/#how-to-set-up-vim","text":"There are two config files: one for vim, otherone for nvim vim: ~/.vimrc nvim: ~/.config/nvim/init.vim I cannot find at this point a config file for vim O.o So, I will just create a .vimrc under my home: Now, given that I have installed in my computer vim and nvim, the way that the configuration files interact, seems that nvim takes prevalence. So, all the changes I made in the ~/.vimrc are not going to be stablished unless I source the vimrc in the init.vim As an example, this is the way my init.vim looks like: \" ============================= \" Source vimrc \" ============================ source ~/.vimrc \" ============================= \" Plugins \" ============================= call plug#begin() Plug 'JuliaEditorSupport/julia-vim' Plug 'kdheepak/JuliaFormatter.vim' Plug 'jpalardy/vim-slime' Plug 'neoclide/coc.nvim', {'branch': 'release'} Plug 'morhetz/gruvbox' call plug#end() \" ============================= \" VIM Slime \" ============================= let g:slime_target = \"neovim\"","title":"How to set up vim"},{"location":"vim_notes/#creating-and-modifying-the-vimrc","text":"vim ~/.vimrc","title":"Creating and modifying the vimrc"},{"location":"vim_notes/#settings-for-vim","text":"First I'm going to edit the vimrc file. One trick to try the configurations that I want, is that if I'm working on vim I can go to normal mode and try for example :set relative number and that will include the modification for that vim session.","title":"Settings for vim"},{"location":"vim_notes/#customizing-vim-plugins","text":"Plugins are for this. Different from the settings that are things that comes already with vim, the plugins are made for this. To use plugins, we need a plugin manager. One of the most used ones is the vim-plug In order to use plugins (after installing the vim-plug) our .vimrc file should contain a section that starts and finish with this: call plug#begin('~/.vim/plugged') call plug#end() Now, if we want to install a plugin, we should write in the middle of those two calls the plugin. Save and then run :PlugInstall And that's it. It will download and install the files needed. As an example, to change a color scheme we can do: call plug#begin('~/.vim/plugged') Plug 'gruvbox-community/gruvbox' call plug#end() After the installation, we can set: :colorscheme gruvbox If I want to know the pluggins installed, and given that we are using the vim-plug we can check the pluggins in use with: :PlugStatus","title":"Customizing vim (plugins)"},{"location":"vim_notes/#working-with-vim-and-git","text":"Is kind of bothering to exit vim in order to commit changes in the git repository, so a way to do it is to use the bang :! to execute shell commands. :!git status :!git commit -m \"Ref #2 my changes done\" :!git push Here we can use the % to indicate current file: :!git add % :!git checkout % To be honest, its easier to open a new window with tmux and execute all terminal commands from there than from the vim session. It's less tipying.","title":"Working with vim and git"},{"location":"vim_notes/#workflow","text":"When changing the .vimrc file","title":"Workflow"},{"location":"vim_notes/#errors","text":"Section with some of the errors that I have faced and followed steps to solve them.","title":"Errors"},{"location":"vim_notes/#coc-nodejs-not-executable","text":"When opening a vim session, always this message will pop-up: \"node\" is not executable, checkout https://nodejs.org/en/download/ To install nodejs and avoid this problem, I did: curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - sudo apt-get install -y nodejs","title":".coc nodejs not executable"},{"location":"vim_notes/#rf-not-starting-r-session","text":"Given that the rf is not working when opening a R file, one of the solutions is to indicate the R path in the .vimrc file, so I included it let R_path = '~/R/x86_64-pc-linux-gnu-library/4.2' Nonetheless, it's still not working.","title":"rf not starting R session"},{"location":"vim_notes/#new-start","text":"So, given that my configuration wasn't working who knows why, I just commented all the .vimrc file and start over again checking what worked and what no. After commenting my .vimrc , I reloaded it. I opened a vim_test.R file, hit \\rf and it worked! Now that it worked, I went through the .vimrc and start uncommenting some of the things that I thought would not affect again nvim-r. The final file looks like this one: \" No compatibility with vi to avoid problems \"set nocompatible \" Source vimrc file if specific project have one \"set exrc \" Cursor as a block set guicursor= \" Use relative numbers in files set relativenumber \" Line where I'm positioned is the real line number set nu \" Avoid leaving highligth after a search is done \"set nohlsearch \" No saving or keeping buffer in the background set hidden \" Indentetation configuration set tabstop=4 softtabstop=4 set shiftwidth=4 set expandtab set smartindent \" Start scrolling until 8 spaces away set scrolloff=8 \" Create extra column set signcolumn=yes \" Mark 80 characters line set colorcolumn=80 \" Enable type file detection \"filetype on \" Enable plugins and load plugins for the detected filetype \"filetype plugin on \" Load an indent file for the detected file type \"filetype indent on \" Set the leader key \"let mapleader=\" \" \" Set encoding \"set encoding=utf-8 \" Plugins \" gruvbox to change color schema \" powerline to obtain bar in bottom with git/project status call plug#begin() \"Plug 'gruvbox-community/gruvbox' Plug 'jalvesaq/Nvim-R' \" To work with vim and R Plug 'preservim/nerdtree' \" View the files Plug 'ncm2/ncm2' \" Auto-complete R commands Plug 'gaalcaras/ncm-R' \" Auto complete R commands call plug#end() \" NERDTree configuration test nnoremap <C-n> :NERDTree<CR> \" Set the R path for plugin nvim-r \"let R_path = '~/R/x86_64-pc-linux-gnu-library/4.2'","title":"New start"},{"location":"vim_notes/#vim-workflow-for-r-projects","text":"Ok, I don't want to spend more time on this configuration thing. So I started using vim to work on my R project just to feel the main pains when switching from RStudio. Along the way, if there is too much pain because of lack of some sort of functionality that I was too attached to it, I will change the .vimrc file to try to relieve some pain. \\rf Connect to R Console \\rq Quit R Console \\d Run current line and move to the next line \\l Run current line, but cursor will stay on the same line. \\pp Run paragraph. But cursor will stay on the same block. \\pd Runs block and move to the next one \\ss Execute a block of selected code . This has to be done with visual mode \\aa Run entire script \\ro Open the \"Global Environment\" ctrl + w + l Jump to left panel ctrl + w + h Jump to right panel If I made a change on the ~/.vimrc file, I can source it with :source ~/.vimcr If I have installed the pluggin NERDTree , I need to remap some keys. At the moment I have in my ~/.vimrc file the line: nnoremap <C-n> :NERDTree<CR> , so I don't have to do :NERDTree to open the file browser. Now this can be done with: ctrl + n Open file browser on left side by default. Inside the file tree browser, I can move with the arrows. To expand one folder and show contents, I can hit ENTER . Doing the same in an open folder, will close it. To move out from the NERDTree browser I can ctrl + w + w so I will be jumping panels from left to right.","title":"vim workflow for R projects"},{"location":"vim_notes/#references","text":"Plugin repos https://github.com/gaalcaras/ncm-R https://github.com/preservim/nerdtree https://github.com/jamespeapen/Nvim-R/wiki/Use Sites that can be useful: https://github.com/nodesource/distributions/blob/master/README.md#debinstall http://manuals.bioinformatics.ucr.edu/home/programming-in-r/vim-r https://hpcc.ucr.edu/manuals_linux-cluster_terminalIDE.html https://gist.github.com/tgirke/7a7c197b443243937f68c422e5471899","title":"References"}]}